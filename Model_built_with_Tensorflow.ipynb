{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport h5py\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.framework.ops import EagerTensor\nfrom tensorflow.python.ops.resource_variable_ops import ResourceVariable\nimport time\nimport os\ntf.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-20T16:27:21.606438Z","iopub.execute_input":"2023-04-20T16:27:21.606881Z","iopub.status.idle":"2023-04-20T16:27:21.619214Z","shell.execute_reply.started":"2023-04-20T16:27:21.606844Z","shell.execute_reply":"2023-04-20T16:27:21.617780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Dataset paths\ntrain_path = '/kaggle/input/broken-eggs/train'\ntest_path = '/kaggle/input/broken-eggs/test'\n\n#Loading TF Datasets\ntraining_dataset, validation_dataset = tf.keras.utils.image_dataset_from_directory(\ntrain_path,\nclass_names=['crack', 'empty', 'good'],\nbatch_size=None,\nimage_size=(480, 360),\nseed=0,\nvalidation_split=0.2,\nsubset='both'\n)\n\ntest_dataset = tf.keras.utils.image_dataset_from_directory(\ntest_path,\nclass_names=['crack', 'empty', 'good'],\nseed=0,\nimage_size=(480, 360),\nbatch_size=None\n)\nprint(training_dataset.element_spec)\nprint(validation_dataset.element_spec)\nprint(test_dataset.element_spec)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T17:32:29.617867Z","iopub.execute_input":"2023-04-20T17:32:29.618406Z","iopub.status.idle":"2023-04-20T17:32:30.001332Z","shell.execute_reply.started":"2023-04-20T17:32:29.618363Z","shell.execute_reply":"2023-04-20T17:32:29.999977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = training_dataset.map(lambda x, y: x)\nY_train = training_dataset.map(lambda x, y: y)\nX_val = validation_dataset.map(lambda x, y: x)\nY_val = validation_dataset.map(lambda x, y: y)\nX_test = test_dataset.map(lambda x, y: x)\nY_test = test_dataset.map(lambda x, y: y)\nprint(X_test.element_spec)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:17:03.596283Z","iopub.execute_input":"2023-04-20T20:17:03.596738Z","iopub.status.idle":"2023-04-20T20:17:03.653400Z","shell.execute_reply.started":"2023-04-20T20:17:03.596699Z","shell.execute_reply":"2023-04-20T20:17:03.652105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize images Function\ndef normalize(image):\n    \"\"\"\n    Transform an image into a tensor of shape (Height * Width * 3, )\n    and normalize its components.\n    \n    Arguments\n    image - Tensor.\n    \n    Returns: \n    result -- Transformed tensor \n    \"\"\"\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.reshape(image, [-1,])\n    return image","metadata":{"execution":{"iopub.status.busy":"2023-04-20T17:35:53.955161Z","iopub.execute_input":"2023-04-20T17:35:53.955647Z","iopub.status.idle":"2023-04-20T17:35:53.963222Z","shell.execute_reply.started":"2023-04-20T17:35:53.955542Z","shell.execute_reply":"2023-04-20T17:35:53.961511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Normalize images\nnew_train = X_train.map(normalize)\nnew_val = X_val.map(normalize)\nnew_test = X_test.map(normalize)\nprint(next(iter(new_test)))\nprint(new_test.element_spec)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:17:48.485557Z","iopub.execute_input":"2023-04-20T20:17:48.486861Z","iopub.status.idle":"2023-04-20T20:17:48.650069Z","shell.execute_reply.started":"2023-04-20T20:17:48.486816Z","shell.execute_reply":"2023-04-20T20:17:48.649142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One-hot encoding function\ndef one_hot_matrix(label, depth=3):\n    \"\"\"\n    Computes the one hot encoding for a single label\n    \n    Arguments:\n        label --  (int) Categorical labels\n        depth --  (int) Number of different classes that label can take\n    \n    Returns:\n         one_hot -- tf.Tensor A single-column matrix with the one hot encoding.\n    \"\"\"\n\n    one_hot = tf.reshape(tf.one_hot(label, depth, axis=0), shape=[-1, ])\n    \n    return one_hot","metadata":{"execution":{"iopub.status.busy":"2023-04-20T18:06:57.506565Z","iopub.execute_input":"2023-04-20T18:06:57.507059Z","iopub.status.idle":"2023-04-20T18:06:57.513695Z","shell.execute_reply.started":"2023-04-20T18:06:57.507017Z","shell.execute_reply":"2023-04-20T18:06:57.512439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#One Hot Encoding\nnew_y_train = Y_train.map(one_hot_matrix)\nnew_y_val = Y_val.map(one_hot_matrix)\nnew_y_test = Y_test.map(one_hot_matrix)\nprint(new_y_train.element_spec)\nprint(next(iter(new_y_train)))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T18:09:23.690382Z","iopub.execute_input":"2023-04-20T18:09:23.690830Z","iopub.status.idle":"2023-04-20T18:09:25.150527Z","shell.execute_reply.started":"2023-04-20T18:09:23.690793Z","shell.execute_reply":"2023-04-20T18:09:25.149219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initialize parameters function\n\ndef initialize_parameters(n_x=518400, n_h1=24, n_h2=12, n_h3=6, n_y=3):\n    \"\"\"\n    Initializes parameters to build a neural network with TensorFlow. The shapes are:\n                        W1 : [n_h1, n_x]\n                        b1 : [n_h1, 1]\n                        W2 : [n_h2, n_h1]\n                        b2 : [n_h2, 1]\n                        W3 : [n_h3, n_h2]\n                        b3 : [n_h3, 1]\n                        W4 : [n_y, n_h3]\n                        b4 : [n_y, 1]\n    Argument:\n    n_x -- size of the input layer\n    n_h1 -- size of the first hidden layer\n    n_h2 -- size of second hidden layer\n    n_h3 -- size of third hidden layer\n    n_y -- size of the output layer\n    \n    Returns:\n    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n    \"\"\"\n                                \n    initializer = tf.keras.initializers.GlorotNormal(seed=1)   \n\n    W1 = tf.Variable(initializer(shape=(n_h1, n_x)))\n    b1 = tf.Variable(initializer(shape=(n_h1, 1)))\n    W2 = tf.Variable(initializer(shape=(n_h2, n_h1)))\n    b2 = tf.Variable(initializer(shape=(n_h2, 1)))\n    W3 = tf.Variable(initializer(shape=(n_h3, n_h2)))\n    b3 = tf.Variable(initializer(shape=(n_h3, 1)))\n    W4 = tf.Variable(initializer(shape=(n_y, n_h3)))\n    b4 = tf.Variable(initializer(shape=(n_y, 1)))\n\n    parameters = {\"W1\": W1,\n                  \"b1\": b1,\n                  \"W2\": W2,\n                  \"b2\": b2,\n                  \"W3\": W3,\n                  \"b3\": b3,\n                  \"W4\": W4,\n                  \"b4\": b4}\n    \n    return parameters","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:35:33.716102Z","iopub.execute_input":"2023-04-20T19:35:33.716489Z","iopub.status.idle":"2023-04-20T19:35:33.728031Z","shell.execute_reply.started":"2023-04-20T19:35:33.716456Z","shell.execute_reply":"2023-04-20T19:35:33.726413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Initialize parameters\nparamaters = initialize_parameters()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:35:41.655331Z","iopub.execute_input":"2023-04-20T19:35:41.655766Z","iopub.status.idle":"2023-04-20T19:35:41.865911Z","shell.execute_reply.started":"2023-04-20T19:35:41.655727Z","shell.execute_reply":"2023-04-20T19:35:41.864921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Forward Propagation Function\n\ndef forward_propagation(X, parameters):\n    \"\"\"\n    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR\n    \n    Arguments:\n    X -- input dataset placeholder, of shape (input size, number of examples)\n    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n                  the shapes are given in initialize_parameters\n\n    Returns:\n    Z3 -- the output of the last LINEAR unit\n    \"\"\"\n    \n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n    W4 = parameters['W4']\n    b4 = parameters['b4']\n    \n    Z1 = tf.math.add(tf.linalg.matmul(W1, X), b1)\n    A1 = tf.keras.activations.relu(Z1)\n    Z2 = tf.math.add(tf.linalg.matmul(W2, A1), b2)\n    A2 = tf.keras.activations.relu(Z2)\n    Z3 = tf.math.add(tf.linalg.matmul(W3, A2), b3)\n    A3 = tf.keras.activations.relu(Z3)\n    Z4 = tf.math.add(tf.linalg.matmul(W4, A3), b4)\n    \n    \n    return Z4","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:40:29.029513Z","iopub.execute_input":"2023-04-20T19:40:29.029951Z","iopub.status.idle":"2023-04-20T19:40:29.038658Z","shell.execute_reply.started":"2023-04-20T19:40:29.029912Z","shell.execute_reply":"2023-04-20T19:40:29.037665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Compute Total Loss Function\n\ndef compute_total_loss(logits, labels):\n    \"\"\"\n    Computes the total loss\n    \n    Arguments:\n    logits -- output of forward propagation (output of the last LINEAR unit)\n    labels -- \"true\" labels vector, same shape as Z4\n    \n    Returns:\n    total_loss - Tensor of the total loss value\n    \"\"\"\n    \n    total_loss = tf.reduce_sum(tf.keras.losses.categorical_crossentropy(tf.transpose(labels), tf.transpose(logits), from_logits=True))\n    \n    # YOUR CODE ENDS HERE\n    return total_loss","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:40:31.300473Z","iopub.execute_input":"2023-04-20T19:40:31.301756Z","iopub.status.idle":"2023-04-20T19:40:31.309277Z","shell.execute_reply.started":"2023-04-20T19:40:31.301694Z","shell.execute_reply":"2023-04-20T19:40:31.307929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Build model\ndef model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n          num_epochs = 1500, minibatch_size = 8, print_cost = True):\n    \"\"\"\n    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n    \n    Arguments:\n    X_train -- training set\n    Y_train -- test set\n    X_val -- validation set\n    Y_val -- validation set\n    learning_rate -- learning rate of the optimization\n    num_epochs -- number of epochs of the optimization loop\n    minibatch_size -- size of a minibatch\n    print_cost -- True to print the cost every 10 epochs\n    \n    Returns:\n    parameters -- parameters learnt by the model. They can then be used to predict.\n    \"\"\"\n    # To keep track of the cost\n    costs = []                       \n    train_acc = []\n    test_acc = []\n    \n    # Initialize your parameters\n    parameters = initialize_parameters()\n\n    W1 = parameters['W1']\n    b1 = parameters['b1']\n    W2 = parameters['W2']\n    b2 = parameters['b2']\n    W3 = parameters['W3']\n    b3 = parameters['b3']\n    W4 = parameters['W4']\n    b4 = parameters['b4']\n    \n    #Optmizer\n    optimizer = tf.keras.optimizers.Adam(learning_rate)\n    \n    # Track the accuracy\n    test_accuracy = tf.keras.metrics.CategoricalAccuracy()\n    train_accuracy = tf.keras.metrics.CategoricalAccuracy()\n    \n    dataset = tf.data.Dataset.zip((X_train, Y_train))\n    test_dataset = tf.data.Dataset.zip((X_test, Y_test))\n    \n    # Get the number of elements\n    m = dataset.cardinality().numpy()\n    \n    minibatches = dataset.batch(minibatch_size).prefetch(4)\n    test_minibatches = test_dataset.batch(minibatch_size).prefetch(4)\n\n    # Do the training loop\n    for epoch in range(num_epochs):\n\n        epoch_total_loss = 0.\n        \n        #We need to reset object to start measuring from 0 the accuracy each epoch\n        train_accuracy.reset_states()\n        \n        for (minibatch_X, minibatch_Y) in minibatches:\n            \n            with tf.GradientTape() as tape:\n                # 1. predict\n                Z4 = forward_propagation(tf.transpose(minibatch_X), parameters)\n\n                # 2. loss\n                minibatch_total_loss = compute_total_loss(Z4, tf.transpose(minibatch_Y))\n\n            # Accumulate the accuracy of all the batches\n            train_accuracy.update_state(minibatch_Y, tf.transpose(Z4))\n            \n            trainable_variables = [W1, b1, W2, b2, W3, b3, W4, b4]\n            grads = tape.gradient(minibatch_total_loss, trainable_variables)\n            optimizer.apply_gradients(zip(grads, trainable_variables))\n            epoch_total_loss += minibatch_total_loss\n        \n        # Divide the epoch total loss over the number of samples\n        epoch_total_loss /= m\n        \n         # Print the cost every 10 epochs\n        if print_cost == True and epoch % 10 == 0:\n            print (\"Cost after epoch %i: %f\" % (epoch, epoch_total_loss))\n            print(\"Train accuracy:\", train_accuracy.result())\n            \n            # Evaluate the test set every 10 epochs to avoid computational overhead\n            for (minibatch_X, minibatch_Y) in test_minibatches:\n                Z4 = forward_propagation(tf.transpose(minibatch_X), parameters)\n                test_accuracy.update_state(minibatch_Y, tf.transpose(Z4))\n            print(\"Test_accuracy:\", test_accuracy.result())\n\n            costs.append(epoch_total_loss)\n            train_acc.append(train_accuracy.result())\n            test_acc.append(test_accuracy.result())\n            test_accuracy.reset_states()\n\n\n    return parameters, costs, train_acc, test_acc","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:40:32.987978Z","iopub.execute_input":"2023-04-20T19:40:32.988408Z","iopub.status.idle":"2023-04-20T19:40:33.007641Z","shell.execute_reply.started":"2023-04-20T19:40:32.988365Z","shell.execute_reply":"2023-04-20T19:40:33.006235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters, costs, train_acc, test_acc = model(new_train, new_y_train, new_val, new_y_val, num_epochs=100, learning_rate=0.0001)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T19:40:33.895230Z","iopub.execute_input":"2023-04-20T19:40:33.895665Z","iopub.status.idle":"2023-04-20T20:08:16.019553Z","shell.execute_reply.started":"2023-04-20T19:40:33.895622Z","shell.execute_reply":"2023-04-20T20:08:16.018419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot cost\nplt.plot(np.squeeze(costs))\nplt.ylabel('cost')\nplt.xlabel('iterations (per fives)')\nplt.title(\"Learning rate =\" + str(0.0001))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:09:03.862180Z","iopub.execute_input":"2023-04-20T20:09:03.863330Z","iopub.status.idle":"2023-04-20T20:09:04.111977Z","shell.execute_reply.started":"2023-04-20T20:09:03.863271Z","shell.execute_reply":"2023-04-20T20:09:04.110685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot train accuracy\nplt.plot(np.squeeze(train_acc))\nplt.ylabel('Train Accuracy')\nplt.xlabel('iterations (per fives)')\nplt.title(\"Learning rate =\" + str(0.0001))\n# Plot test accuracy\nplt.plot(np.squeeze(test_acc))\nplt.ylabel('Test Accuracy')\nplt.xlabel('iterations (per fives)')\nplt.title(\"Learning rate =\" + str(0.0001))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:09:18.423876Z","iopub.execute_input":"2023-04-20T20:09:18.425301Z","iopub.status.idle":"2023-04-20T20:09:18.635952Z","shell.execute_reply.started":"2023-04-20T20:09:18.425229Z","shell.execute_reply":"2023-04-20T20:09:18.634683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parameters['W1']","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:30:43.325994Z","iopub.execute_input":"2023-04-20T20:30:43.326900Z","iopub.status.idle":"2023-04-20T20:30:43.336395Z","shell.execute_reply.started":"2023-04-20T20:30:43.326856Z","shell.execute_reply":"2023-04-20T20:30:43.335420Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluation using test set\nclass_names = ['crack', 'empty', 'good']\ntest_dataset = tf.data.Dataset.zip((new_test, Y_test))\nfor (x_test, y_test) in test_dataset:\n    Z4 = forward_propagation(tf.reshape(x_test, (518400,1)), parameters)\n    #print(Z4)\n    softmax = tf.nn.softmax(tf.transpose(Z4))\n    print(softmax)\n    print(\n    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n    .format(class_names[np.argmax(softmax)], 100 * np.max(softmax))\n    )","metadata":{"execution":{"iopub.status.busy":"2023-04-20T20:41:41.170104Z","iopub.execute_input":"2023-04-20T20:41:41.170503Z","iopub.status.idle":"2023-04-20T20:41:41.559620Z","shell.execute_reply.started":"2023-04-20T20:41:41.170466Z","shell.execute_reply":"2023-04-20T20:41:41.558293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}